ðŸ§  How It Works

Document Ingestion â€“ PDFs and DOCX are parsed and split into semantic chunks

Embedding Generation â€“ SentenceTransformers converts chunks to embeddings

Vector Search â€“ FAISS retrieves top-k relevant chunks

RAG Generation â€“ Ollama LLM generates an answer using retrieved context

Memory â€“ Conversation history is stored for multi-turn context

âœ… Recruiter/Interview Highlights

Fully offline, enterprise-grade RAG chatbot

Windows-ready setup using free tools

Modular design â€“ easy to extend with new documents, models, or UI features

Demonstrates skills in Python, LLMs, vector search, and enterprise architecture

ðŸ“„ References

LangChain Docs

FAISS

SentenceTransformers

Streamlit

Ollama LLM

ðŸ’¡ Next Steps / Improvements

Add metadata filtering for department-specific queries

Implement document version tracking

Integrate additional LLMs for comparison (e.g., Mistral 7B)

Add speech-to-text / text-to-speech interface for accessibility
